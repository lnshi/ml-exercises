{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the awesome original post here: [What is Bootstrap Sampling in Statistics and Machine Learning?](https://www.analyticsvidhya.com/blog/2020/02/what-is-bootstrap-sampling-in-statistics-and-machine-learning/)\n",
    "\n",
    "## What is bootstrapping (bootstrap sampling)?\n",
    "\n",
    "Before deep dive into the ensemble learning, it is very important to understand the `bootstrapping (bootstrap sampling)` concept.\n",
    "\n",
    "> In statistics, Bootstrap Sampling is a method that involves drawing of sample data repeatedly with replacement from a data source to estimate a population parameter.\n",
    "\n",
    "That is too complex, lets break it down and understand the key terms:\n",
    "\n",
    "- __Sampling__: With respect to statistics, sampling is the process of selecting a subset of items from a vast collection of items (population) to estimate a certain characteristic of the entire population\n",
    "    \n",
    "- __Sampling with replacement__: It means a data point in a drawn sample can reappear in future drawn samples as well\n",
    "    \n",
    "- __Parameter estimation__: It is a method of estimating parameters for the population using samples. A parameter is a measurable characteristic associated with a population. For example, the average height of residents in a city, the count of red blood cells, etc.\n",
    "\n",
    "## Why do we need bootstrap sampling?\n",
    "\n",
    "This is a fundamental question I’ve seen machine learning enthusiasts grapple with. What is the point of Bootstrap Sampling? Where can you use it? Let me take an example to explain this.\n",
    "\n",
    "Let’s say we want to find the mean height of all the students in a school (which has a total population of 1,000). So, how can we perform this task?\n",
    "\n",
    "One approach is to measure the height of all the students and then compute the mean height.\n",
    "\n",
    "However, this would be a tedious task. Just think about it, we would have to individually measure the heights of 1,000 students and then compute the mean height. It will take days! We need a smarter approach here.\n",
    "\n",
    "This is where Bootstrap Sampling comes into play.\n",
    "\n",
    "Instead of measuring the heights of all the students, we can draw a random sample of 5 students and measure their heights. We would repeat this process 20 times and then average the collected height data of 100 students (5 x 20). This average height would be an estimate of the mean height of all the students of the school.\n",
    "\n",
    "Pretty straightforward, right? This is the basic idea of Bootstrap Sampling.\n",
    "\n",
    "## Implement Bootstrap Sampling in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a Gaussian distribution (population) of 10,000 elements with the population mean being 500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0092224010808"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal distribution \n",
    "x = np.random.normal(loc= 500.0, scale=1.0, size=10000)\n",
    "\n",
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will draw 40 samples of size 5 from the distribution (population) and compute the mean for every sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = []\n",
    "\n",
    "# Bootstrap sampling\n",
    "for i in range(40):\n",
    "  y = random.sample(x.tolist(), 5)\n",
    "  avg = np.mean(y)\n",
    "  sample_mean.append(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the average of the mean values of all the 40 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499.9273237399751"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sample_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out to be pretty close to the population mean! This is why Bootstrap Sampling is such a useful technique in statistics and machine learning.\n",
    "\n",
    "Here are a few key benefits of bootstrapping:\n",
    "\n",
    "- The estimated parameter by bootstrap sampling is comparable to the actual population parameter;\n",
    "\n",
    "- Since we only need a few samples for bootstrapping, the computation requirement is very less;\n",
    "\n",
    "- In Random Forest, the bootstrap sample size of even 20% gives a pretty good performance;\n",
    "\n",
    "- The model performance reaches maximum when the data provided is less than 0.2 fraction of the original dataset;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is ensemble learning\n",
    "\n",
    "Ensemble learning __strategically generate (what kind of weak learners to use)__ a set of different models, and then __strategically combine (how to combine/merge/select the different predictions from different weak learners)__ the decisions from each of the models to eventually solve a complex problem better (improve the overall performance: higher accuracy, more proper bias-variance balancing)\n",
    "\n",
    "Common methods:\n",
    "\n",
    "- Boosting\n",
    "\n",
    "- Bagging\n",
    "\n",
    "- Stacking\n",
    "\n",
    "### Boosting\n",
    "\n",
    "The general idea behind boosting methods is to train predictors sequentially, each trying to correct its predecessor. The two most commonly used boosting algorithms are AdaBoost and Gradient Boosting.\n",
    "\n",
    "It often considers __homogeneous weak learners__, learns them __sequentially__ in a very adaptive way (a base model depends on the previous ones) and combines them by following a deterministic strategy.\n",
    "\n",
    "In sequential methods the different combined weak models are no longer fitted independently from each others. The idea is to fit models iteratively such that the training of model at a given step depends on the models fitted at the previous steps. `Boosting` is the most famous of these approaches and it produces an ensemble model that is in general less biased than the weak learners that compose it.\n",
    "\n",
    "### Bagging\n",
    "\n",
    "It often considers __homogeneous weak learners__, learns them independently from each other __in parallel__ and combines them following some kind of deterministic averaging process.\n",
    "\n",
    "### Stacking\n",
    "\n",
    "It often considers __heterogeneous weak learners__, learns them __in parallel__ and combines them by training a meta-model to output a prediction based on the different weak models predictions.\n",
    "\n",
    "Stacking mainly differ from bagging and boosting on two points:\n",
    "\n",
    "- First stacking often considers __heterogeneous weak learners__ (different learning algorithms are combined) whereas bagging and boosting consider mainly __homogeneous weak learners__.\n",
    "\n",
    "- Second, stacking learns to combine the base models using a __meta-model__ whereas bagging and boosting combine weak learners following __deterministic algorithms__."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "427px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
