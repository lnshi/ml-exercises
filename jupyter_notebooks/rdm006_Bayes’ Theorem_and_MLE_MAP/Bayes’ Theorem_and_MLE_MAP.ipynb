{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Theorem\n",
    "\n",
    "In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule) describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if cancer is related to age, then, using Bayes' theorem, a person's age can be used to more accurately assess the probability that they have cancer, compared to the assessment of the probability of cancer made without knowledge of the person's age.\n",
    "\n",
    "Bayesian inference derives the [posterior probability](https://en.wikipedia.org/wiki/Posterior_probability) as a [consequence](https://en.wikipedia.org/wiki/Consequence_relation) of two [antecedents](https://en.wikipedia.org/wiki/Antecedent_(logic)): a [prior probability](https://en.wikipedia.org/wiki/Prior_probability) and a \"[likelihood function](https://en.wikipedia.org/wiki/Likelihood_function)\" derived from a [statistical model](https://en.wikipedia.org/wiki/Statistical_model) for the observed data. Bayesian inference computes the posterior probability according to Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  P(H|E) &= \\frac{P(E|H)P(H)}{P(E)} &\\qquad \\text{(1)} \\\\\n",
    "  \\Rightarrow P(H|E) &= \\frac{P(E|H)P(H)}{P(E|H)P(H) + P(E|\\bar{H})P(\\bar{H})} \\enspace (\\bar{H} \\text{ means 'not H'}) &\\qquad \\text{(2)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- **|** means 'event conditional on' (so that (A|B) means A given B);\n",
    "\n",
    "- **H** stands for any hypothesis whose probability may be affected by data (called __evidence__ below). Often there are competing hypotheses, and the task is to determine which is the most probable;\n",
    "\n",
    "- **P(H)**, the [prior probability](https://en.wikipedia.org/wiki/Prior_probability), is the estimate of the probability of the hypothesis H before the data E, the current evidence, is observed;\n",
    "\n",
    "- **E** (evidence) corresponds to new data that were not used in computing the prior probability;\n",
    "\n",
    "- **P(H|E)**, the [posterior probability](https://en.wikipedia.org/wiki/Posterior_probability), is the probability of H given E, i.e., after E is observed. This is what we want to know: the probability of a hypothesis given the observed evidence;\n",
    "\n",
    "- **P(E|H)** is the probability of observing E given H, and is called the [likelihood](https://en.wikipedia.org/wiki/Likelihood_function). As a function of E with H fixed, it indicates the compatibility of the evidence with the given hypothesis. The likelihood function is a function of the evidence E, while the posterior probability is a function of the hypothesis H;\n",
    "\n",
    "- **P(E)** is sometimes termed the [marginal likelihood](https://en.wikipedia.org/wiki/Marginal_likelihood) or 'model evidence'. This factor is the same for all possible hypotheses being considered (as is evident from the fact that the hypothesis H does not appear anywhere in the symbol, unlike for all the other factors), so this factor does not enter into determining the relative probabilities of different hypotheses;\n",
    "\n",
    "#### Probability Function and Likelihood Function\n",
    "\n",
    "To function $P(E|H)$:\n",
    "\n",
    "- **Probability Function**\n",
    "  - If **H** is fixed, and __E__ is the independent variable, then this function is called probability function, which tells the occurrence probability of each evidence E by given H;\n",
    "  \n",
    "  \n",
    "- **Likelihood Function**\n",
    "  - If **E** is fixed, and __H__ is the independent variable, then this function is called likelihood function, which tells the occurrence probability of this fixed evidence E under different H;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE (Maximum Likelihood Estimation)\n",
    "\n",
    "Combine with above **Likelihood Function** definition, MLE is such an estimation: trying to find out the H which has the most probability to make the known E happen.\n",
    "\n",
    "Lets walk MLE through the classical game 'coin flipping':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解](https://blog.csdn.net/u011508640/article/details/72815981)\n",
    "\n",
    "- [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)\n",
    "\n",
    "- [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
