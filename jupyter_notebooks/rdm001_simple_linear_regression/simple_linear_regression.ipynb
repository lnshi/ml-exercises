{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sets the backend of matplotlib to the 'inline' backend.\n",
    "#\n",
    "# With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook,\n",
    "# directly below the code cell that produced it.\n",
    "# The resulting plots will then also be stored in the notebook document.\n",
    "#\n",
    "# More details: https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data in, and then show the first several rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/data.csv'\n",
    "data = pd.read_csv(path, sep=',', header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some basic high level statistical overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the data in Cartesian coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', x='Population', y='Profit', figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the latest squares cost function\n",
    "\n",
    "Lets say we have sample data set: \n",
    "\n",
    "$$\n",
    "(x_1, y_1),(x_2, y_2), (x_3, y_3)\n",
    "$$\n",
    "\n",
    "And we want to find out the coefficient matrix $\\theta = \\begin{pmatrix} \\theta_0 & \\theta_1\\end{pmatrix}$ for the fitting equation:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "y \\> = \\> \\theta_0 \\> + \\> \\theta_1x\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "to minimize the quadratic sum of each sample data's itting error $\\varepsilon_i$, that is: $\\sum\\limits_{i=1}^3\\varepsilon_i^2$, which the $\\varepsilon_i$ can be calculated in the below way:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y_1 = \\theta_0 + \\theta_1x_1 + \\varepsilon_1 \\\\\n",
    "y_2 = \\theta_0 + \\theta_1x_2 + \\varepsilon_2 \\\\\n",
    "y_3 = \\theta_0 + \\theta_1x_3 + \\varepsilon_3\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum\\limits_{i=1}^3\\varepsilon_i^2\n",
    "= [(\\theta_0 + \\theta_1x_1) - y_1]^2 + [(\\theta_0 + \\theta_1x_2) - y_2]^2 + [(\\theta_0 + \\theta_1x_3) - y_3]^2 \\\\\n",
    "= [\\begin{pmatrix} 1 & x_1\\end{pmatrix}\\begin{pmatrix} \\theta_0 \\\\ \\theta_1\\end{pmatrix} - y_1]^2 \\\n",
    "  + [\\begin{pmatrix} 1 & x_2\\end{pmatrix}\\begin{pmatrix} \\theta_0 \\\\ \\theta_1\\end{pmatrix} - y_2]^2 \\\n",
    "  + [\\begin{pmatrix} 1 & x_3\\end{pmatrix}\\begin{pmatrix} \\theta_0 \\\\ \\theta_1\\end{pmatrix} - y_3]^2 \\\\\n",
    "= \\sum\\limits_{i=1}^3[\\begin{pmatrix} 1 & x_i\\end{pmatrix}\\theta^T - y_i]^2\n",
    "$$\n",
    "\n",
    "#### So we got two points from the above calculations\n",
    "1. Cost function.\n",
    "2. We need to insert one all **1** column to all the sample data to make the matrix calculations can be performed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the latest squares cost function.\n",
    "def computeCost(X, y, theta):\n",
    "    inner = np.power((X * theta.T) - y, 2)\n",
    "    # The '1/2' is just for calculation convenience, since we know we will use ‘gradient descent’ algorithm,\n",
    "    # and the cost function is one second derived function which after derivative there will be one '2' there.\n",
    "    return np.sum(inner) / (2 * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, 'Ones', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X (training data) any y (target variable).\n",
    "cols = data.shape[1]\n",
    "X = data.iloc[:, 0:cols-1]\n",
    "y = data.iloc[:, cols-1:cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frames to numpy matrices.\n",
    "X = np.matrix(X.values)\n",
    "y = np.matrix(y.values)\n",
    "theta = np.matrix(np.array([0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always pay attention to the shape of the matrix to get around of some unnecessary troubles.\n",
    "X.shape, y.shape, theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the initial coefficient matrix θ to compute the cost.\n",
    "computeCost(X, y, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, iters):\n",
    "    temp = np.matrix(np.zeros(theta.shape))\n",
    "    params = int(theta.ravel().shape[1])\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        error = (X * theta.T) - y\n",
    "        \n",
    "        for j in range(params):\n",
    "            term = np.multiply(error, X[:, j])\n",
    "            temp[0, j] = theta[0, j] - ((alpha / len(X))) * np.sum(term)\n",
    "            \n",
    "        theta = temp\n",
    "        cost[i] = computeCost(X, y, theta)\n",
    "        \n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise learning rate and iterations.\n",
    "alpha = 0.01\n",
    "iters = 1000\n",
    "\n",
    "# Perform gradient descent to find out the coefficient matrix θ for the fitting equation.\n",
    "g, cost = gradientDescent(X, y, theta, alpha, iters)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeCost(X, y, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(data.Population.min(), data.Population.max(), 100)\n",
    "f = g[0, 0] + g[0, 1] * x\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(x, f, 'r', label='Prediction')  \n",
    "ax.scatter(data.Population, data.Profit, label='Traning Data')  \n",
    "ax.legend(loc=2)  \n",
    "ax.set_xlabel('Population')  \n",
    "ax.set_ylabel('Profit')  \n",
    "ax.set_title('Predicted Profit vs. Population Size') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))  \n",
    "ax.plot(np.arange(iters), cost, 'r')  \n",
    "ax.set_xlabel('Iterations')  \n",
    "ax.set_ylabel('Cost')  \n",
    "ax.set_title('Error vs. Training Epoch') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
